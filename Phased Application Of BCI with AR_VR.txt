Phased Application Of BCI with AR/VR 






1. Introduction:


I'm interested in exploring the potential of brain-computer interfaces (BCIs) and motor imagery (MI) control
I'm interested in the idea of mind-controlled music. My project is pretty simple: I want to use brain signals to change songs on Spotify, like a hands-free remote.
Further building upon that  I would like to integrate AR/VR and create BCI-Based Interfaces for AR/VR


2. Existing Research/Projects:
Projects 
Open BCIs Galea and NeuroSky MindWave do a similar thing 
Research Documents 
 
Kohli, Varun, et al. "A review on Virtual Reality and Augmented Reality use-cases of Brain Computer Interface based applications for smart cities." Microprocessors and Microsystems 88 (2022): 104392.


H. Si-Mohammed et al., "Towards BCI-Based Interfaces for Augmented Reality: Feasibility, Design and Evaluation," in IEEE Transactions on Visualization and Computer Graphics, vol. 26, no. 3, pp. 1608-1621, 1 March 2020, doi: 10.1109/TVCG.2018.2873737.
keywords: {Augmented reality;Electroencephalography;Headphones;Resists;Aerospace electronics;Integrated optics;Robots;Brain-computer interface;augmented reality;user interface;design space;SSVEP;optical see-through;robot control},


Frontiers | Editorial: Brain-Computer Interfaces and Augmented/Virtual Reality (frontiersin.org)
https://robohub.org/engineers-build-brain-controlled-music-player/
https://arxiv.org/pdf/1811.06040v1.pdf


3. Development 
Phase 1: Brain-Controlled Music Player:


It is a very basic idea but I would like to implement it to get my hands dirty,the science behind it is here Engineers build brain-controlled music player - Robohub
I would also have to integrate the data with a music player like spotify/youtube music so that it works easily 
Phase 2: Integration with AR/VR:


Further down the line I would also like to use Non Invasive BCIs to help users play games or experience AR/VR without even moving!


The process would involve using the same Steady-State Visually Evoked Potential (SSVEP) which was also used in the first phase 
The process I would follow would be similar to the process given her 1811.06040v1.pdf (arxiv.org)


4. Major Challenges:


* Movement of the head can alter the EEG data collection.In the Towards BCI-Based Interfaces for Augmented Reality: Feasibility, Design and Evaluation | IEEE Journals & Magazine | IEEE Xplore it is mentioned that they could only get accurate data with small movement of the head.That  would limit the usage of the headset
* Accuracy and reliability of MI detection: EEG signals can be noisy and individual differences exist, making accurate MI interpretation challenging.
* Real-time processing and latency: We would need low latency and real-time processing so that the experience is not diluted.
* Technical complexity of AR/VR : It would require proficiency in AR\VR and how to connect it with BCIs.
5. Addressing the Challenges:
* Utilise sophisticated BCI algorithms: We could use advanced algos that would help us extract more useful data .Although it would require a tradeoff between the computation time and latency but it would make the data much more usable 
* Optimise hardware and software: Choose efficient EEG headsets and implement real-time processing algorithms to minimise latency.We would also have to do the data processing on the headset itself so that latency can be minimised 
* Collaborate with experts: Collaborate with the AR\VR vertical of club to implement this